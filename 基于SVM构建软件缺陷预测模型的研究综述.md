#### 基于SVM构建软件缺陷预测模型的研究综述

##### 文献检索方法

在知网以软件缺陷预测为主题，按照相关度排序

在IEEE数据库以software defect prediction为关键字，按照相关度降序排序

摘要：

1. 说一下软件缺陷
2. 软件缺陷预测的意义和价值
3. 影响软件缺陷预测的三个重要因素
4. 引出，缺陷预测模型的构建方法，本文侧重在最传统也是最广泛的SVM
5. 目的：总结至今SVM在构建软件缺陷预测模型
   - 选取了怎样的度量元设计，数据集是什么，是如何处理的
   - 对SVM算法的优化
   - 在论文中都有什么表现
   - 与其它机器学习算法做一个简单的比较
   - 总结SVM算法在构建软件缺陷预测模方面的优势与劣势，适合什么样的场景（即设计怎么样的度量元，面对怎么样的数据集）

##### 摘要



##### 引言

缺陷是软件产品期望属性的偏离，是软件故障和软件失效的源头。[1]其存在于软件的任何生命周期，检测、修复缺陷的时间越晚，所需的代价也越大。然而，给予一个项目的时间、人力资源都是有限的，如何尽早、精确地定位缺陷是产业界的迫切需求。

软件缺陷预测[2,3]是目前一种可行的方案，通过挖掘、分析软件代码历史仓库，借助机器学习等方法构建缺陷预测模型是学界与工业界研究的主要方向。根据陈翔等人【4】对静态软件缺陷预测[2]的研究，静态软件缺陷预测有三个主要影响因素：软件度量元的设定、缺陷预测模型的构建方法和缺陷预测数据集处理相关问题。本文将分析机器学习中使用最广泛的方法——支持向量机（SVM）在构建缺陷预测模型中的应用。

结合陈翔等人的研究成果【4】，为了更好地分析使用SVM构建缺陷预测模型的特点，本文将对以SVM构建缺陷预测模型的【一个数字，目前13】文章从以下几个方面做出总结

- 实验所用的原始数据集是什么，做了怎样的预处理

- 度量元是如何设计的

- 以何种方式考量缺陷的存在（缺陷倾向性、缺陷密度、缺陷数、其它）【4】

- 如何解决类不平衡问题

- SVM是如何被使用的，是否对SVM算法做出了优化与改进

- 最后的结果表现如何

最后本文将对SVM与其它机器学习构建缺陷预测模型做一个简单的比较，并总结SVM在构建软件缺陷预测模方面的优势与劣势，适合什么样的场景。

为了对该问题进行系统地分析。。。。

本文第一部分介绍了综述文章内使用SVM构建缺陷预测模型的工作框架，第二部分就不同文章介绍的改进方法做出总结，第三部分对SVM与其它机器学习构建缺陷预测模型做一个简单的比较，并总结SVM在构建软件缺陷预测模方面的优势与劣势，适合什么样的场景。

##### 1 相关工作

1.1 支持向量机

SVM 是在 1995 年由 Cortes 和 Vapnik 提出的一种基于学习理论和结构风险最小化原则的统计机器学习算法，它的实质是一种监督学习的分类算法，在解决小样本、非线性及高维模式识别中表现出许多特有的优势。SVM 的基本思想是求解核函数和二次线性规划问题，可以通过核函数将线性不可分样本映射到高维空间，找到最优的分类平面作为决策曲面，所谓最优的分类平面就是求解一个平面g( x) = wx + b，使得正例与反例之间的隔离边缘被最大化，即样本的几何间距最大，从而进行分类计算。SVM常用的核函数有 3 种: 径向基核函数 ( Radial BasisFunction，RBF) 、多项式函数和线性核函数， 其中径向基核函数因为有较宽的收敛范围， 被广泛地应用在SVM 中。

1.2 缺陷数据集

1.2.1 数据集面临的问题

1.2.2 数据集的预处理

1.3 度量元的选择

1.4 模型评估方法

##### 2 研究综述

2.1 数据维度灾难

2.2 类不平衡

2.3 SVM的参数优化选择

##### 3 SVM使用总结

3.1 SVM的特点

3.2 与其他机器学习的比较

3.3 SVM的优劣势



##### ACO-SVM

- 原始数据集：NASA数据包（http :// mdp .ivv.nasa .gov/ ）的13个数据集
- 预处理：使用主成分分析（PCA）进行数据降维
- 度量元：软件复杂度度量
- 如何考量缺陷的存在：根据ERROR_COUNT属性，每个数据集中ERROR_COUNT≥1 的模块为有缺陷模块
- 算法运作流程：使用SVM构建预测模型，通过ACO循环优化SVM的C与α参数，直到预测精度达到阈值或循环次数达到上限。ACO优化过程简述：使用模型的准确率（Accuracy）来取代路径长度来更新信息素，蚂蚁在10x10的图上走完一条路径后 , 根据小数点的位置可以计算图上的有效位与有效值 , 根据最优路径就能计算出离散化了的模型的最优参数C与α。
- 结果表现：使用十折交叉验证，采用准确度、查准率、查全率、F1值来评价模型的预测能力，与Fisher 线性
  判别分析(LDA)、聚类分析 (CA )、BP 神经网络(BPNN)、逻辑回归(LR)、支持向量机(SVM ) 进行比较，实验表明在13个数据集上四种评价标准均优于五种方法。从文章提供的实验结果看查全率85%-80%，F1值82%-77%，查全率89%-76%，准确度82%-77%，性能提升约为5%
- 方法弊端：优化过程计算量大、速度慢

##### SVM-DP

- 原始数据集NASA 公布的 NASA IV＆V Facility Metrics Data Program( MDP) 数据集 

- 预处理

  1. 删除原始数据集中的 Module 属性 
  2. 按 error － count 属
     性的值添加 defective 类标记属性 
  3. 补充了error_density属性如 error － density 属性， 按照
     MDP 的相关说明文档， error － density = 1000 × ( error－count /loc－total)  
  4. 所有属性值除了 defective 以外均进行正则化处理 
  5. 避免模型无效化必须将 error － count 属性和 error －
     density 属性以及 KC1 中的 Error － report － in － 1 － yr 等
     三个相关属性从各数据集中删除 

- 度量元：软件度量元：静态代码属性LOC、McCabe 以及 Halstead

- 核心逻辑：对正在开发项目的当前版本进行预测 以期发现包含潜在缺陷的代码单元， 报告缺陷分布信息甚至
  预测修补缺陷的工作量， 从而指导软件测试人员将有限的成本资源集中到最需要的地方。预测得到的缺陷信息可以追加到历史数据中， 形成增量式的历史数据集合。 当进入项目新的生命周期后， 由增量的历史数据集中抽取代码属性并训练生成增强的预测模型 advanced SVM-DP， 进一步完成对新版本项目的预测工作。 

- 结果表现比较了线性内积核函数( Linear) 、径
  向基内积核函数( RBF) 、多项式核函数( Polynomial)
  以及采用神经元的非线性作用函数 Sigmoid 作为内
  积的核函数四种核函数对性能的影响，使用混淆矩阵与ROC、AUC评价，最后在13个数据上得到的结果为

  | 0. 712 | 0. 202 | 0. 790 | 0. 742 | 0. 053 | 0. 000 | 0. 604 | 0. 096 | 0. 548 | 0. 200 | 0. 701 | 0. 573 | 0. 514 | 0. 224 | 0. 694 | 0. 581 |
  | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ |
  |        |        |        |        |        |        |        |        |        |        |        |        |        |        |        |        |

其中RBF核函数与ACO-SVM比较，表现要差于SVM的表现。在 分 别 由 C、C + + 、JAVA 以 及 Perl 开 发 的
MW1、MC1、KC3、KC4 四 个 数 据 集 上 SVM-DP ( liSVM) 比缺陷预测中常用的 J48 表现出更优秀的预
测性能 